{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMsVdIGYloebVarboYFbIcz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Load model directly\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"upstage/SOLAR-10.7B-Instruct-v1.0\")\n","model = AutoModelForCausalLM.from_pretrained(\"upstage/SOLAR-10.7B-Instruct-v1.0\")"],"metadata":{"id":"COW7CGFXEY70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"VXCq97JxRR8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","model.generate(tokenizer(\"hi\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"e45ezP5fQeN6","executionInfo":{"status":"error","timestamp":1710324276196,"user_tz":-540,"elapsed":3,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"3f5ce25f-000c-4109-f38d-19787c44eb8d"},"execution_count":6,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'shape'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f9e37eddaee8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         )\n\u001b[0;32m-> 1376\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;31m# 4. Define other model kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: "]}]},{"cell_type":"code","source":["pipe(\"hi\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFlI2A10NpRr","executionInfo":{"status":"ok","timestamp":1710323796269,"user_tz":-540,"elapsed":67423,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"8d7bdd06-4880-4840-8be1-f82566cd241c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': \"hiatus, and the band's future.\\n\\nIn conclusion, the article provides an overview\"}]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["pipe('한국어로 답변할 수 있어?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V583HDEUNrqv","executionInfo":{"status":"ok","timestamp":1710323818606,"user_tz":-540,"elapsed":22339,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"bc3ee800-d700-4bde-d128-59dc7e565fa8"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': '한국어로 답변할 수 있어?\\n\\n3. Trans'}]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["pipe('안녕')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rl9SqPB6N8FK","executionInfo":{"status":"ok","timestamp":1710323879097,"user_tz":-540,"elapsed":60501,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"452fe373-95dd-4548-c28e-fa0d78d2c774"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': '안녕\\n\\nStep 3: Translate the individual words and phrases\\n-'}]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["pipe('llm에 관해서 설명해줘')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZKX2p4rYOQQD","executionInfo":{"status":"ok","timestamp":1710323907095,"user_tz":-540,"elapsed":28001,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"bf3a4cf8-541f-42bb-c317-040025744b3a"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'llm에 관해서 설명해줘\\n\\nStep 1:'}]"]},"metadata":{},"execution_count":5}]}]}